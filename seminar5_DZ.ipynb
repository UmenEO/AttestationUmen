{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UmenEO/AttestationUmen/blob/main/seminar5_DZ.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqYGgEBoKF9F"
      },
      "source": [
        "# Setting up Colab environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh6zoBplKF9G",
        "outputId": "adfeb519-b481-45be-f82b-230bf1f5f00f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'ITP-SeqRecSys-2024'...\n",
            "remote: Enumerating objects: 84, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (60/60), done.\u001b[K\n",
            "remote: Total 84 (delta 30), reused 67 (delta 17), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (84/84), 580.45 KiB | 8.66 MiB/s, done.\n",
            "Resolving deltas: 100% (30/30), done.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "username = 'recspert'\n",
        "repo = 'ITP-SeqRecSys-2024'\n",
        "\n",
        "# remove local directory if it already exists\n",
        "if os.path.isdir(repo):\n",
        "    !rm -rf {repo}\n",
        "\n",
        "!git clone https://github.com/{username}/{repo}.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4nuoPohKF9H",
        "outputId": "019f33f8-2823-400c-b75a-a3c25ef05a23"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting polara\n",
            "  Cloning https://github.com/evfro/polara.git (to revision develop) to /tmp/pip-install-c7w880_e/polara_c771cced7f0f4bc4bf9d59c4a627312e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/evfro/polara.git /tmp/pip-install-c7w880_e/polara_c771cced7f0f4bc4bf9d59c4a627312e\n",
            "  Running command git checkout -b develop --track origin/develop\n",
            "  Switched to a new branch 'develop'\n",
            "  Branch 'develop' set up to track remote branch 'develop' from 'origin'.\n",
            "  Resolved https://github.com/evfro/polara.git to commit ef7a5360e3f9793f4f0fdd4f31e32399d2e52069\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: polara\n",
            "  Building wheel for polara (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polara: filename=polara-0.7.2.dev0-py3-none-any.whl size=89422 sha256=b1d16d2a6832621977c972a2040f3e328e2d628fb844e5f9229af531ef732268\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-herkoh00/wheels/3f/3a/1f/42058978e585b23c384652846b96b72870f3c8c12976cdac50\n",
            "Successfully built polara\n",
            "Installing collected packages: polara\n",
            "Successfully installed polara-0.7.2.dev0\n"
          ]
        }
      ],
      "source": [
        "!pip install --no-cache-dir --upgrade git+https://github.com/evfro/polara.git@develop#egg=polara"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpTWjqwaKF9H",
        "outputId": "50986b63-6d53-4296-edaf-fbfe7a159c1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/ITP-SeqRecSys-2024\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "from math import ceil\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from numba.typed import List\n",
        "from numba import njit\n",
        "from random import seed as set_seed\n",
        "\n",
        "from time import time\n",
        "\n",
        "from polara import get_movielens_data\n",
        "from polara.preprocessing.dataframes import reindex, leave_one_out\n",
        "\n",
        "# navigating to cloned repo directory in Colab\n",
        "%cd {repo}\n",
        "from source.dataprep.dataprep import split_data_global_timepoint\n",
        "from source.evaluation.evaluation import topn_recommendations, model_evaluate, downvote_seen_items\n",
        "%cd -"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qexICHN-KF9H"
      },
      "outputs": [],
      "source": [
        "def fix_torch_seed(seed):\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMe9caTGKF9H"
      },
      "source": [
        "# Preparing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYAdLV76CipP"
      },
      "outputs": [],
      "source": [
        "data = get_movielens_data(include_time=True)\n",
        "data_description = {\n",
        "    'users':'userid',\n",
        "    'items':'movieid',\n",
        "    'feedback':'rating',\n",
        "    'timestamp':'timestamp'\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wdka5BVAB8XJ"
      },
      "outputs": [],
      "source": [
        "training, testset_valid_, holdout_valid_, testset_, holdout_, data_index, data_description = split_data_global_timepoint(data=data, data_description=data_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PahNxVL8KF9K"
      },
      "source": [
        "Let's focus on validation part. For convenience, let us also reindex the test users."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwQ7VYxVKF9K"
      },
      "outputs": [],
      "source": [
        "userid = data_index['users'].name\n",
        "test_users = pd.Index(\n",
        "    # ensure test users are the same across testing data\n",
        "    np.intersect1d(\n",
        "        testset_valid_[userid].unique(),\n",
        "        holdout_valid_[userid].unique()\n",
        "    )\n",
        ")\n",
        "testset_valid = (\n",
        "    testset_valid_\n",
        "    # reindex warm-start users for convenience\n",
        "    .assign(**{userid: lambda x: test_users.get_indexer(x[userid])})\n",
        "    .query(f'{userid} >= 0')\n",
        "    .sort_values('userid')\n",
        ")\n",
        "holdout_valid = (\n",
        "    holdout_valid_\n",
        "    # reindex warm-start users for convenience\n",
        "    .assign(**{userid: lambda x: test_users.get_indexer(x[userid])})\n",
        "    .query(f'{userid} >= 0')\n",
        "    .sort_values('userid')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "eTKtYWnqJzK2",
        "outputId": "ca51f077-27dd-4bae-bee8-dcb7bfb7f9aa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userid       736\n",
              "movieid      551\n",
              "rating         5\n",
              "timestamp    736\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>userid</th>\n",
              "      <td>736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movieid</th>\n",
              "      <td>551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <td>736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "holdout_valid.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w7KlCCtikaHZ"
      },
      "outputs": [],
      "source": [
        "testset = (\n",
        "    testset_\n",
        "    # reindex warm-start users for convenience\n",
        "    .assign(**{userid: lambda x: test_users.get_indexer(x[userid])})\n",
        "    .query(f'{userid} >= 0')\n",
        "    .sort_values('userid')\n",
        ")\n",
        "holdout = (\n",
        "    holdout_\n",
        "    # reindex warm-start users for convenience\n",
        "    .assign(**{userid: lambda x: test_users.get_indexer(x[userid])})\n",
        "    .query(f'{userid} >= 0')\n",
        "    .sort_values('userid')\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "Z-NR13IdKyNw",
        "outputId": "2a7bff95-4fff-4297-dcf5-147153a6eec7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "userid       736\n",
              "movieid      574\n",
              "rating         5\n",
              "timestamp    736\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>userid</th>\n",
              "      <td>736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>movieid</th>\n",
              "      <td>574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>rating</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>timestamp</th>\n",
              "      <td>736</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "holdout.nunique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v3NerS7eKF9K"
      },
      "outputs": [],
      "source": [
        "assert holdout_valid.set_index('userid')['timestamp'].ge(\n",
        "    testset_valid\n",
        "    .groupby('userid')\n",
        "    ['timestamp'].max()\n",
        ").all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZFt44BcdKF9L",
        "outputId": "4f6b356a-32c2-4870-a775-d2477d17b4ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'users': 'userid',\n",
              " 'items': 'movieid',\n",
              " 'order': 'timestamp',\n",
              " 'n_users': 5227,\n",
              " 'n_items': 3652}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data_description = dict(\n",
        "    users = data_index['users'].name,\n",
        "    items = data_index['items'].name,\n",
        "    order = 'timestamp',\n",
        "    n_users = len(data_index['users']),\n",
        "    n_items = len(data_index['items']),\n",
        ")\n",
        "data_description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu-2akKsKF9L"
      },
      "source": [
        "# Batch Sampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Warcm9oj7W8"
      },
      "outputs": [],
      "source": [
        "from random import randrange\n",
        "import numpy as np\n",
        "\n",
        "@njit(fastmath=True)\n",
        "def sample_unseen(sample_size, sampler_state, remaining, result):\n",
        "    \"\"\"\n",
        "    Sample a desired number of integers from a range (starting from zero)\n",
        "    excluding black-listed elements defined in sample state. Used with in\n",
        "    conjunction with `prime_sample_state` method, which initializes state.\n",
        "    Inspired by Fischer-Yates shuffle.\n",
        "    \"\"\"\n",
        "    # gradually sample from the decreased size range\n",
        "    for k in range(sample_size):\n",
        "        i = randrange(remaining) # Randomly select an index in the range of remaining items\n",
        "        result[k] = sampler_state.get(i, i) # Fetch item or assign i if not found in state\n",
        "        remaining -= 1 # Decrease the remaining number of items\n",
        "        sampler_state[i] = sampler_state.get(remaining, remaining)\n",
        "        sampler_state.pop(remaining, -1) # Remove the last item from the sampler state\n",
        "\n",
        "@njit(fastmath=True)\n",
        "def prime_sampler_state(n, exclude):\n",
        "    \"\"\"\n",
        "    Initialize state to be used in `sample_unseen_items`.\n",
        "    Ensures seen items are never sampled by placing them\n",
        "    outside of sampling region.\n",
        "    \"\"\"\n",
        "    # initialize typed numba dicts\n",
        "    state = {n: n}; state.pop(n)\n",
        "    track = {n: n}; track.pop(n)\n",
        "\n",
        "    n_pos = n - len(state) - 1\n",
        "    # reindex excluded items, placing them in the end\n",
        "    for i, item in enumerate(exclude):\n",
        "        pos = n_pos - i\n",
        "        x = track.get(item, item)\n",
        "        t = state.get(pos, pos)\n",
        "        state[x] = t\n",
        "        track[t] = x\n",
        "        state.pop(pos, n)\n",
        "        track.pop(item, n)\n",
        "    return state"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ddHRkgtxisTm"
      },
      "outputs": [],
      "source": [
        "@njit\n",
        "def sample_without_rep(user_items, maxlen, pad_token, n_neg_samples, itemnum, seed):\n",
        "    # generate n_neg_samples in case of BCE loss\n",
        "\n",
        "    seq = np.full(maxlen, pad_token, dtype=np.int32)\n",
        "    pos = np.full(maxlen, pad_token, dtype=np.int32)\n",
        "    neg = np.full((maxlen, n_neg_samples), pad_token, dtype=np.int32)\n",
        "\n",
        "    hist_items_counter = 1\n",
        "    nxt = user_items[-1]\n",
        "    idx = maxlen - 1\n",
        "\n",
        "    set_seed(seed)\n",
        "\n",
        "    ts_ = list(set(user_items))\n",
        "\n",
        "    for i in user_items[-2::-1]:\n",
        "        seq[idx] = i\n",
        "        pos[idx] = nxt\n",
        "\n",
        "        state = prime_sampler_state(itemnum, ts_)\n",
        "        remaining = itemnum - len(ts_)\n",
        "\n",
        "        sample_unseen(n_neg_samples, state, remaining, neg[idx])\n",
        "\n",
        "        nxt = i\n",
        "        idx -= 1\n",
        "        hist_items_counter += 1\n",
        "        if idx == -1:\n",
        "            break\n",
        "\n",
        "    neg = np.swapaxes(neg, 0, 1)\n",
        "    return seq, pos, neg\n",
        "\n",
        "def no_sample(user_items, maxlen, pad_token):\n",
        "    # return positive, leave negative empty\n",
        "    # used for CE and SCE\n",
        "\n",
        "    seq = np.full(maxlen, pad_token, dtype=np.int32)\n",
        "    pos = np.full(maxlen, pad_token, dtype=np.int32)\n",
        "    neg = np.empty((maxlen, 1))\n",
        "\n",
        "    n_user_items = min(len(user_items) - 1, maxlen)\n",
        "\n",
        "    seq[-n_user_items:] = user_items[-n_user_items-1:-1]\n",
        "    pos[-n_user_items:] = user_items[-n_user_items:]\n",
        "\n",
        "    return seq, pos, neg\n",
        "\n",
        "class SequentialDataset(Dataset):\n",
        "    def __init__(self, user_train, usernum, itemnum, maxlen, seed, n_neg_samples=1, sampling='without_rep', pad_token=None):\n",
        "        super().__init__()\n",
        "        self.user_train = user_train\n",
        "\n",
        "        self.valid_users = [user for user in range(usernum) if len(user_train.get(user, [])) > 1]\n",
        "\n",
        "        self.usernum = len(self.valid_users)\n",
        "\n",
        "        self.itemnum = itemnum\n",
        "        self.maxlen = maxlen\n",
        "        self.seed = seed\n",
        "        self.n_neg_samples = n_neg_samples\n",
        "        self.sampling = sampling\n",
        "\n",
        "        self.pad_token = pad_token\n",
        "\n",
        "        self.random_state = np.random.RandomState(self.seed)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.usernum\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        user = self.valid_users[idx]\n",
        "        user_items = List()\n",
        "        [user_items.append(x) for x in self.user_train[user]]\n",
        "\n",
        "        if self.sampling == 'without_rep':\n",
        "            seq, pos, neg = sample_without_rep(user_items, self.maxlen, self.pad_token, self.n_neg_samples, self.itemnum, self.random_state.randint(np.iinfo(int).min, np.iinfo(int).max))\n",
        "\n",
        "        elif self.sampling == 'no_sampling':\n",
        "            seq, pos, neg = no_sample(user_items, self.maxlen, self.pad_token)\n",
        "\n",
        "        return user, seq, pos, neg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZTXNYdmKF9L"
      },
      "source": [
        "# SASRec model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0DeZnNBKF9L"
      },
      "source": [
        "The code is adapted from https://github.com/pmixer/SASRec.pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SDi6J5iLBbcx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "outputId": "0c471cc8-5ab4-40bf-9e49-e18431aa4eb5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "class PointWiseFeedForward(nn.Module):\n",
        "    def __init__(self, hidden_units, dropout_rate):\n",
        "\n",
        "        super(PointWiseFeedForward, self).__init__()\n",
        "\n",
        "        self.conv1 = nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
        "        self.dropout1 = nn.Dropout(p=dropout_rate)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv1d(hidden_units, hidden_units, kernel_size=1)\n",
        "        self.dropout2 = nn.Dropout(p=dropout_rate)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        outputs = self.dropout2(self.conv2(self.relu(self.dropout1(self.conv1(inputs.transpose(-1, -2))))))\n",
        "        outputs = outputs.transpose(-1, -2) # as Conv1D requires (N, C, Length)\n",
        "        outputs += inputs\n",
        "        return outputs\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class SASRecBackBone(nn.Module):\n",
        "    def __init__(self, item_num, config):\n",
        "        super(SASRecBackBone, self).__init__()\n",
        "        self.item_num = item_num\n",
        "        self.pad_token = item_num\n",
        "\n",
        "        self.item_emb = nn.Embedding(self.item_num+1, config['hidden_units'], padding_idx=self.pad_token)\n",
        "        self.pos_emb = nn.Embedding(config['maxlen'], config['hidden_units'])\n",
        "        self.emb_dropout = nn.Dropout(p=config['dropout_rate'])\n",
        "\n",
        "        self.attention_layernorms = nn.ModuleList() # to be Q for self-attention\n",
        "        self.attention_layers = nn.ModuleList()\n",
        "        self.forward_layernorms = nn.ModuleList()\n",
        "        self.forward_layers = nn.ModuleList()\n",
        "        self.last_layernorm = nn.LayerNorm(config['hidden_units'], eps=1e-8)\n",
        "\n",
        "        for _ in range(config['num_blocks']):\n",
        "            new_attn_layernorm = nn.LayerNorm(config['hidden_units'], eps=1e-8)\n",
        "            self.attention_layernorms.append(new_attn_layernorm)\n",
        "            new_attn_layer =  nn.MultiheadAttention(\n",
        "                config['hidden_units'], config['num_heads'], config['dropout_rate']\n",
        "            )\n",
        "            self.attention_layers.append(new_attn_layer)\n",
        "\n",
        "            new_fwd_layernorm = nn.LayerNorm(config['hidden_units'], eps=1e-8)\n",
        "            self.forward_layernorms.append(new_fwd_layernorm)\n",
        "\n",
        "            new_fwd_layer = PointWiseFeedForward(config['hidden_units'], config['dropout_rate'])\n",
        "            self.forward_layers.append(new_fwd_layer)\n",
        "\n",
        "        fix_torch_seed(config['manual_seed'])\n",
        "        self.initialize()\n",
        "\n",
        "    def initialize(self):\n",
        "        for _, param in self.named_parameters():\n",
        "            try:\n",
        "                torch.nn.init.xavier_uniform_(param.data)\n",
        "            except:\n",
        "                pass # just ignore those failed init layers\n",
        "\n",
        "    def log2feats(self, log_seqs):\n",
        "        device = log_seqs.device\n",
        "\n",
        "        seqs = self.item_emb(log_seqs)\n",
        "        seqs *= self.item_emb.embedding_dim ** 0.5\n",
        "        positions = np.tile(np.arange(log_seqs.shape[1]), [log_seqs.shape[0], 1])\n",
        "        seqs += self.pos_emb(torch.LongTensor(positions).to(device))\n",
        "        seqs = self.emb_dropout(seqs)\n",
        "\n",
        "        timeline_mask = log_seqs == self.pad_token\n",
        "        seqs *= ~timeline_mask.unsqueeze(-1) # broadcast in last dim\n",
        "\n",
        "        tl = seqs.shape[1] # time dim len for enforce causality\n",
        "        attention_mask = ~torch.tril(torch.full((tl, tl), True, device=device))\n",
        "\n",
        "        all_attn_weights = []  #    \n",
        "\n",
        "        for i in range(len(self.attention_layers)):\n",
        "            seqs = torch.transpose(seqs, 0, 1)\n",
        "            Q = self.attention_layernorms[i](seqs)\n",
        "\n",
        "            #       \n",
        "            mha_outputs, attn_weights = self.attention_layers[i](\n",
        "                Q, seqs, seqs, attn_mask=attention_mask\n",
        "            )\n",
        "\n",
        "            all_attn_weights.append(attn_weights)  #   \n",
        "\n",
        "            seqs = Q + mha_outputs\n",
        "            seqs = torch.transpose(seqs, 0, 1)\n",
        "\n",
        "            seqs = self.forward_layernorms[i](seqs)\n",
        "            seqs = self.forward_layers[i](seqs)\n",
        "            seqs *= ~timeline_mask.unsqueeze(-1)\n",
        "\n",
        "        log_feats = self.last_layernorm(seqs)  # (U, T, C) -> (U, -1, C)\n",
        "\n",
        "        #    \n",
        "        avg_attn_weights = [torch.mean(weights, dim=0).detach().cpu() for weights in all_attn_weights]\n",
        "\n",
        "        return log_feats, avg_attn_weights\n",
        "\n",
        "    def forward(self, log_seqs, pos_seqs, neg_seqs):\n",
        "        log_feats, avg_attn_weights = self.log2feats(log_seqs)\n",
        "        pos_embs = self.item_emb(pos_seqs)\n",
        "        neg_embs = self.item_emb(neg_seqs)\n",
        "\n",
        "        pos_logits = (log_feats * pos_embs).sum(dim=-1)\n",
        "        neg_logits = (log_feats[:, None, :, :] * neg_embs).sum(dim=-1)\n",
        "\n",
        "        return pos_logits, neg_logits, avg_attn_weights\n",
        "\n",
        "#    \n",
        "def plot_attention_heatmap(attn_weights, layer=0):\n",
        "    sns.heatmap(attn_weights[layer], cmap=\"viridis\")\n",
        "    plt.title(f'Attention Weights for Layer {layer+1}')\n",
        "    plt.show()\n",
        "\n",
        "class SASRec(SASRecBackBone):\n",
        "    def __init__(self, item_num, config):\n",
        "        super().__init__(item_num + 1, config)\n",
        "\n",
        "        self.fwd_type = config['fwd_type']\n",
        "\n",
        "        if self.fwd_type == 'bce':\n",
        "            self.n_neg_samples = config['n_neg_samples']\n",
        "\n",
        "        if self.fwd_type == 'sce':\n",
        "            self.n_buckets = config['n_buckets']\n",
        "            self.bucket_size_x = eval(config['bucket_size_x']) if type(config['bucket_size_x']) == str else config['bucket_size_x']\n",
        "            self.bucket_size_y = eval(config['bucket_size_y']) if type(config['bucket_size_y']) == str else config['bucket_size_y']\n",
        "\n",
        "            self.mix_x = config['mix_x']\n",
        "\n",
        "\n",
        "    def forward(self, log_seqs, pos_seqs, neg_seqs):\n",
        "        if self.fwd_type == 'bce':\n",
        "            return self.bce_forward(log_seqs, pos_seqs, neg_seqs)\n",
        "\n",
        "        elif self.fwd_type == 'ce':\n",
        "            return self.ce_forward(log_seqs, pos_seqs)\n",
        "\n",
        "        if self.fwd_type == 'sce':\n",
        "            return self.sce_forward(log_seqs, pos_seqs)\n",
        "\n",
        "        else:\n",
        "            raise ValueError(f'Wrong fwd_type type - {self.fwd_type}')\n",
        "\n",
        "    def bce_forward(self, log_seqs, pos_seqs, neg_seqs):\n",
        "        device = log_seqs.device\n",
        "        pos_logits, neg_logits = super().forward(log_seqs, pos_seqs, neg_seqs)\n",
        "\n",
        "        pos_logits = pos_logits[:, :, None]\n",
        "        neg_logits = neg_logits.permute(0, 2, 1)\n",
        "\n",
        "        pos_labels = torch.ones(pos_logits.shape, device=device)\n",
        "        neg_labels = torch.zeros(neg_logits.shape, device=device)\n",
        "\n",
        "        logits = torch.cat([pos_logits, neg_logits], -1)\n",
        "\n",
        "        gt = torch.cat([pos_labels, neg_labels], -1)\n",
        "\n",
        "        mask = (pos_seqs != self.pad_token).float()\n",
        "\n",
        "        loss_per_element = torch.nn.functional.binary_cross_entropy_with_logits(logits, gt, reduction='none').mean(-1) * mask\n",
        "        loss = loss_per_element.sum() / mask.sum()\n",
        "\n",
        "        return loss\n",
        "\n",
        "    def ce_forward(self, log_seqs, pos_seqs):\n",
        "        emb = self.log2feats(log_seqs)\n",
        "        logits = emb @ self.item_emb.weight.T\n",
        "        indices = torch.where(pos_seqs.view(-1) != self.pad_token)\n",
        "        loss = F.cross_entropy(logits.view(-1, logits.shape[-1])[indices], pos_seqs.view(-1)[indices], reduction='mean')\n",
        "        return loss\n",
        "\n",
        "    def sce_forward(self, log_seqs, pos_seqs):\n",
        "        emb = self.log2feats(log_seqs)\n",
        "        hd = emb.shape[-1]\n",
        "\n",
        "        x = emb.view(-1, hd)\n",
        "        y = pos_seqs.view(-1)\n",
        "        w = self.item_emb.weight\n",
        "\n",
        "        correct_class_logits_ = (x * torch.index_select(w, dim=0, index=y)).sum(dim=1) # (bs,)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if self.mix_x:\n",
        "                omega = 1/np.sqrt(np.sqrt(hd)) * torch.randn(x.shape[0], self.n_buckets, device=x.device)\n",
        "                buckets = omega.T @ x\n",
        "                del omega\n",
        "            else:\n",
        "                buckets = 1/np.sqrt(np.sqrt(hd)) * torch.randn(self.n_buckets, hd, device=x.device) # (n_b, hd)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            x_bucket = buckets @ x.T # (n_b, hd) x (hd, b) -> (n_b, b)\n",
        "            x_bucket[:, log_seqs.view(-1) == self.pad_token] = float('-inf')\n",
        "            _, top_x_bucket = torch.topk(x_bucket, dim=1, k=self.bucket_size_x) # (n_b, bs_x)\n",
        "            del x_bucket\n",
        "\n",
        "            y_bucket = buckets @ w.T # (n_b, hd) x (hd, n_cl) -> (n_b, n_cl)\n",
        "\n",
        "            y_bucket[:, self.pad_token] = float('-inf')\n",
        "            _, top_y_bucket = torch.topk(y_bucket, dim=1, k=self.bucket_size_y) # (n_b, bs_y)\n",
        "            del y_bucket\n",
        "\n",
        "        x_bucket = torch.gather(x, 0, top_x_bucket.view(-1, 1).expand(-1, hd)).view(self.n_buckets, self.bucket_size_x, hd) # (n_b, bs_x, hd)\n",
        "        y_bucket = torch.gather(w, 0, top_y_bucket.view(-1, 1).expand(-1, hd)).view(self.n_buckets, self.bucket_size_y, hd) # (n_b, bs_y, hd)\n",
        "\n",
        "        wrong_class_logits = (x_bucket @ y_bucket.transpose(-1, -2)) # (n_b, bs_x, bs_y)\n",
        "        mask = torch.index_select(y, dim=0, index=top_x_bucket.view(-1)).view(self.n_buckets, self.bucket_size_x)[:, :, None] == top_y_bucket[:, None, :] # (n_b, bs_x, bs_y)\n",
        "        wrong_class_logits = wrong_class_logits.masked_fill(mask, float('-inf')) # (n_b, bs_x, bs_y)\n",
        "        correct_class_logits = torch.index_select(correct_class_logits_, dim=0, index=top_x_bucket.view(-1)).view(self.n_buckets, self.bucket_size_x)[:, :, None] # (n_b, bs_x, 1)\n",
        "        logits = torch.cat((wrong_class_logits, correct_class_logits), dim=2) # (n_b, bs_x, bs_y + 1)\n",
        "\n",
        "        loss_ = F.cross_entropy(logits.view(-1, logits.shape[-1]), (logits.shape[-1] - 1) * torch.ones(logits.shape[0] * logits.shape[1], dtype=torch.int64, device=logits.device), reduction='none') # (n_b * bs_x,)\n",
        "        loss = torch.zeros(x.shape[0], device=x.device, dtype=x.dtype)\n",
        "        loss.scatter_reduce_(0, top_x_bucket.view(-1), loss_, reduce='amax', include_self=False)\n",
        "        loss = loss[(loss != 0) & (y != self.pad_token)]\n",
        "        loss = torch.mean(loss)\n",
        "\n",
        "        return loss\n",
        "\n",
        "config = {\n",
        "    'hidden_units': 64,\n",
        "    'maxlen': 50,\n",
        "    'dropout_rate': 0.2,\n",
        "    'num_blocks': 2,\n",
        "    'num_heads': 4,\n",
        "    'manual_seed': 42\n",
        "}\n",
        "\n",
        "#    (,  )\n",
        "item_num = 1000\n",
        "\n",
        "#  \n",
        "model = SASRecBackBone(item_num, config)\n",
        "\n",
        "#   ( ,    )\n",
        "log_seqs = torch.randint(0, item_num, (32, config['maxlen']))  #   32 \n",
        "pos_seqs = torch.randint(0, item_num, (32, config['maxlen']))  #  \n",
        "neg_seqs = torch.randint(0, item_num, (32, config['maxlen']))  #  \n",
        "\n",
        "#    \n",
        "pos_logits, neg_logits, avg_attn_weights = model.forward(log_seqs, pos_seqs, neg_seqs)\n",
        "\n",
        "#      \n",
        "plot_attention_heatmap(avg_attn_weights, layer=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuv1sLfwKF9M"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pvld-ngXKF9M"
      },
      "outputs": [],
      "source": [
        "def data_to_sequences(data, data_description):\n",
        "    userid = data_description['users']\n",
        "    itemid = data_description['items']\n",
        "    sequences = (\n",
        "        data.sort_values([userid, data_description['order']])\n",
        "        .groupby(userid, sort=False)[itemid].apply(list)\n",
        "    )\n",
        "    return sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T6PNap7QKF9M"
      },
      "outputs": [],
      "source": [
        "def prepare_sasrec_model(config, data, data_description):\n",
        "    n_users = data_description['n_users']\n",
        "    n_items = data_description['n_items']\n",
        "    model = SASRec(n_items, config)\n",
        "    if torch.cuda.is_available():\n",
        "        model = model.cuda()\n",
        "\n",
        "    train_sequences = data_to_sequences(data, data_description)\n",
        "    sampler = DataLoader(SequentialDataset(train_sequences, n_users, n_items,\n",
        "        maxlen = config['maxlen'],\n",
        "        seed = config['sampler_seed'],\n",
        "        n_neg_samples = config['n_neg_samples'],\n",
        "        pad_token = model.pad_token,\n",
        "        sampling = config['sampling']), batch_size=config['batch_size'], shuffle=True, num_workers=2, pin_memory=True, prefetch_factor=10, drop_last=True)\n",
        "\n",
        "    n_batches = len(train_sequences) // config['batch_size']\n",
        "    optimizer = torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr = config['learning_rate'],\n",
        "        betas = (0.9, 0.98)\n",
        "    )\n",
        "    return model, sampler, n_batches, optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yLUzxVSSKF9M"
      },
      "outputs": [],
      "source": [
        "def train_sasrec_epoch(model, num_batch, l2_emb, sampler, optimizer, device):\n",
        "    model.train()\n",
        "    pad_token = model.pad_token\n",
        "    losses = []\n",
        "    for _, *seq_data in sampler:\n",
        "        # convert batch data into torch tensors\n",
        "        seq, pos, neg = (torch.LongTensor(np.array(x)).to(device) for x in seq_data)\n",
        "        loss = model(seq, pos, neg)\n",
        "        optimizer.zero_grad()\n",
        "        if l2_emb != 0:\n",
        "          for param in model.item_emb.parameters():\n",
        "            loss += l2_emb * torch.norm(param) ** 2\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        losses.append(loss.item())\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qnhYJ4fnds-"
      },
      "outputs": [],
      "source": [
        "def sasrec_model_scoring(params, data, data_description):\n",
        "    model = params\n",
        "    model.eval()\n",
        "    tensor = torch.cuda.LongTensor if torch.cuda.is_available() else torch.LongTensor\n",
        "    test_sequences = data_to_sequences(data, data_description)\n",
        "    # perform scoring on a user-batch level\n",
        "    scores = []\n",
        "    for _, seq in test_sequences.items():\n",
        "        with torch.no_grad():\n",
        "          predictions = model.score(tensor(seq))\n",
        "        scores.append(predictions.detach().cpu().numpy())\n",
        "    return np.concatenate(scores, axis=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H7eyOkq_KF9M"
      },
      "outputs": [],
      "source": [
        "def build_sasrec_model(config, data, data_description):\n",
        "    '''Simple MF training routine without early stopping'''\n",
        "    model, sampler, n_batches, optimizer = prepare_sasrec_model(config, data, data_description)\n",
        "    device = 'cpu'\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(f'cuda:{torch.cuda.current_device()}')\n",
        "    losses = {}\n",
        "    hr, mrr, cov = {}, {}, {}\n",
        "    best_hr = 0\n",
        "    wait = 0\n",
        "    start_time = time()\n",
        "    torch.cuda.synchronize()\n",
        "    torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "    for epoch in tqdm(range(config['num_epochs'])):\n",
        "        losses[epoch] = train_sasrec_epoch(\n",
        "            model, n_batches, config['l2_emb'], sampler, optimizer, device\n",
        "        )\n",
        "        val_scores = sasrec_model_scoring(model, testset_valid, data_description)\n",
        "        downvote_seen_items(val_scores, testset_valid, data_description)\n",
        "        val_recs = topn_recommendations(val_scores, topn=10)\n",
        "        metrics = model_evaluate(val_recs, holdout_valid, data_description)\n",
        "        hr_ = metrics['hr']\n",
        "        mrr_ = metrics['mrr']\n",
        "        cov_ = metrics['cov']\n",
        "\n",
        "        hr[epoch] = hr_\n",
        "        mrr[epoch] = mrr_\n",
        "        cov[epoch] = cov_\n",
        "\n",
        "        if hr_ > best_hr:\n",
        "          best_hr = hr_\n",
        "          wait = 0\n",
        "        elif wait < 20:\n",
        "          wait += 1\n",
        "        else:\n",
        "          break\n",
        "\n",
        "    torch.cuda.synchronize()\n",
        "    training_time_sec = time() - start_time\n",
        "    full_peak_training_memory_bytes = torch.cuda.max_memory_allocated()\n",
        "    training_epoches = len(losses)\n",
        "\n",
        "    print('Peak training memory, mb:', round(full_peak_training_memory_bytes/ 1024. / 1024., 2))\n",
        "    print('Training epoches:', training_epoches)\n",
        "    print('Training time, m:', round(training_time_sec/ 60., 2))\n",
        "\n",
        "    return model, losses, hr, mrr, cov"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "br2tSmGtzvdD"
      },
      "outputs": [],
      "source": [
        "base_config_test = dict(\n",
        "    num_epochs = 1,\n",
        "    maxlen = 200,\n",
        "    hidden_units = 64,\n",
        "    dropout_rate = 0.4,\n",
        "    num_blocks = 2,\n",
        "    num_heads = 1,\n",
        "    batch_size = 2048,\n",
        "    sampler_seed = 99,\n",
        "    manual_seed = 111,\n",
        "    learning_rate = 1e-3,\n",
        "    l2_emb = 0,\n",
        "    n_neg_samples = 0,\n",
        "    sampling = 'no_sampling',\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423,
          "referenced_widgets": [
            "67cc7e90602c4777af7dc3e7b6af2a36",
            "1be0fbd8ab63491aa711d6154092c0f3",
            "2f7defdc24bc48289f9668e40c9cc4ee",
            "4db7a72e29c447dd8278b85b1aa04314",
            "02fee2945cab42f68c759465bbbaf3e5",
            "87195f84835b4d59b30324085cf1e367",
            "512fe5bc570d48008ef4405c3148fc72",
            "42a45a724fc04e06a9830c50fab4c9ec",
            "9c19b3e2d27f4e1fa584ae3b4520e924",
            "a7fa3469952e457f843ebc689d59e1d6",
            "145c4429030147b3bf4c4d048c298252"
          ]
        },
        "id": "bwk6fTRHjMZu",
        "outputId": "bd2cb414-9cf2-4531-a760-8f5e05840043"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "67cc7e90602c4777af7dc3e7b6af2a36"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 47.06 MiB is free. Process 3063 has 14.70 GiB memory in use. Of the allocated memory 14.45 GiB is allocated by PyTorch, and 112.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-45b01acc6c77>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mconfig_sce_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'fwd_type'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'sce'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mmodel_sce_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses_sce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhr_sce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmrr_sce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_sce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_sasrec_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig_sce_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_description\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-32-024105d18e3c>\u001b[0m in \u001b[0;36mbuild_sasrec_model\u001b[0;34m(config, data, data_description)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'num_epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         losses[epoch] = train_sasrec_epoch(\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_batches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l2_emb'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         )\n",
            "\u001b[0;32m<ipython-input-30-5631b72544fe>\u001b[0m in \u001b[0;36mtrain_sasrec_epoch\u001b[0;34m(model, num_batch, l2_emb, sampler, optimizer, device)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;31m# convert batch data into torch tensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseq_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0ml2_emb\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-9fd7a2300e60>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, log_seqs, pos_seqs, neg_seqs)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfwd_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sce'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 148\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msce_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-9fd7a2300e60>\u001b[0m in \u001b[0;36msce_forward\u001b[0;34m(self, log_seqs, pos_seqs)\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msce_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0memb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog2feats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0mhd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-9fd7a2300e60>\u001b[0m in \u001b[0;36mlog2feats\u001b[0;34m(self, log_seqs)\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_seqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mseqs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_seqs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0mseqs\u001b[0m \u001b[0;34m*=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem_emb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mpositions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_seqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlog_seqs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m         return F.embedding(\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m             self.norm_type, self.scale_grad_by_freq, self.sparse)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2265\u001b[0m         \u001b[0;31m# remove once script supports set_grad_enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2266\u001b[0m         \u001b[0m_no_grad_embedding_renorm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_norm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2267\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscale_grad_by_freq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2268\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 100.00 MiB. GPU 0 has a total capacity of 14.75 GiB of which 47.06 MiB is free. Process 3063 has 14.70 GiB memory in use. Of the allocated memory 14.45 GiB is allocated by PyTorch, and 112.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "config_sce_test = base_config_test.copy()\n",
        "config_sce_test['mix_x'] = True\n",
        "config_sce_test['n_buckets'] = 500\n",
        "config_sce_test['bucket_size_x'] = 500\n",
        "config_sce_test['bucket_size_y'] = 200\n",
        "config_sce_test['fwd_type'] = 'sce'\n",
        "\n",
        "model_sce_test, losses_sce, hr_sce, mrr_sce, cov_sce = build_sasrec_model(config_sce_test, training, data_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F0kGxlkfjGT3"
      },
      "outputs": [],
      "source": [
        "config_ce_test = base_config_test.copy()\n",
        "config_ce_test['fwd_type'] = 'ce'\n",
        "\n",
        "model_ce_test, losses_ce, hr_ce, mrr_ce, cov_ce = build_sasrec_model(config_ce_test, training, data_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "21b40ooujHVO"
      },
      "outputs": [],
      "source": [
        "config_bce_test = base_config_test.copy()\n",
        "config_bce_test['fwd_type'] = 'bce'\n",
        "config_bce_test['n_neg_samples'] = 32\n",
        "config_bce_test['sampling'] = 'without_rep'\n",
        "\n",
        "model_bce_test, losses_bce, hr_bce, mrr_bce, cov_bce = build_sasrec_model(config_bce_test, training, data_description)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fsEF5X9wfOg"
      },
      "source": [
        "# Let's train the models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SI8O6J3RTU7O"
      },
      "outputs": [],
      "source": [
        "base_config = dict(\n",
        "    num_epochs = 20,\n",
        "    maxlen = 200,\n",
        "    hidden_units = 64,\n",
        "    dropout_rate = 0.4,\n",
        "    num_blocks = 2,\n",
        "    num_heads = 1,\n",
        "    batch_size = 256,\n",
        "    sampler_seed = 99,\n",
        "    manual_seed = 111,\n",
        "    learning_rate = 1e-3,\n",
        "    l2_emb = 0,\n",
        "    sampling = 'no_sampling',\n",
        "    n_neg_samples = 0\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yHoivRZUiDlv"
      },
      "outputs": [],
      "source": [
        "config_bce = base_config.copy()\n",
        "config_bce['fwd_type'] = 'bce'\n",
        "config_bce['n_neg_samples'] = 32\n",
        "config_bce['sampling'] = 'without_rep'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CXkoiAI6iGGE"
      },
      "outputs": [],
      "source": [
        "model_bce, losses_bce, hr_bce, mrr_bce, cov_bce = build_sasrec_model(config_bce, training, data_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oRakZwaHKF9M"
      },
      "outputs": [],
      "source": [
        "config_ce = base_config.copy()\n",
        "config_ce['fwd_type'] = 'ce'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_SNulmhcKF9N"
      },
      "outputs": [],
      "source": [
        "model_ce, losses_ce, hr_ce, mrr_ce, cov_ce = build_sasrec_model(config_ce, training, data_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FI-qYJlildVj"
      },
      "outputs": [],
      "source": [
        "config_sce = base_config.copy()\n",
        "config_sce['mix_x'] = False\n",
        "config_sce['n_buckets'] = 500\n",
        "config_sce['bucket_size_x'] = 500\n",
        "config_sce['bucket_size_y'] = 200\n",
        "config_sce['fwd_type'] = 'sce'\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uq0p6TRolgbE"
      },
      "outputs": [],
      "source": [
        "model_sce, losses_sce, hr_sce, mrr_sce, cov_sce = build_sasrec_model(config_sce, training, data_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSwWjM1lljYZ"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1, 4, figsize=(20, 5))\n",
        "pd.Series(losses_sce).apply(np.mean).plot(title='Evolution of loss', xlabel='Epoch', ylabel='Loss', ax=ax[0], label='SCE');\n",
        "pd.Series(hr_sce).apply(np.mean).plot(title='Evolution of val HR', xlabel='Epoch', ylabel='HR', ax=ax[1], label='SCE');\n",
        "pd.Series(mrr_sce).apply(np.mean).plot(title='Evolution of val MRR', xlabel='Epoch', ylabel='MRR', ax=ax[2], label='SCE');\n",
        "pd.Series(cov_sce).apply(np.mean).plot(title='Evolution of val COV', xlabel='Epoch', ylabel='COV', ax=ax[3], label='SCE');\n",
        "\n",
        "pd.Series(losses_ce).apply(np.mean).plot(title='Evolution of loss', xlabel='Epoch', ylabel='Loss', ax=ax[0], label='CE');\n",
        "pd.Series(hr_ce).apply(np.mean).plot(title='Evolution of val HR', xlabel='Epoch', ylabel='HR', ax=ax[1], label='CE');\n",
        "pd.Series(mrr_ce).apply(np.mean).plot(title='Evolution of val MRR', xlabel='Epoch', ylabel='MRR', ax=ax[2], label='CE');\n",
        "pd.Series(cov_ce).apply(np.mean).plot(title='Evolution of val COV', xlabel='Epoch', ylabel='COV', ax=ax[3], label='CE');\n",
        "\n",
        "pd.Series(losses_bce).apply(np.mean).plot(title='Evolution of loss', xlabel='Epoch', ylabel='Loss', ax=ax[0], label='BCE');\n",
        "pd.Series(hr_bce).apply(np.mean).plot(title='Evolution of val HR', xlabel='Epoch', ylabel='HR', ax=ax[1], label='BCE');\n",
        "pd.Series(mrr_bce).apply(np.mean).plot(title='Evolution of val MRR', xlabel='Epoch', ylabel='MRR', ax=ax[2], label='BCE');\n",
        "pd.Series(cov_bce).apply(np.mean).plot(title='Evolution of val COV', xlabel='Epoch', ylabel='COV', ax=ax[3], label='BCE');\n",
        "\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iplbj61KF9N"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "67GnPui2iuon"
      },
      "outputs": [],
      "source": [
        "# SASRec BCE\n",
        "sasrec_scores_bce = sasrec_model_scoring(model_bce, testset, data_description)\n",
        "downvote_seen_items(sasrec_scores_bce, testset, data_description)\n",
        "\n",
        "sasrec_recs_bce = topn_recommendations(sasrec_scores_bce, topn=10)\n",
        "model_evaluate(sasrec_recs_bce, holdout, data_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69ocQuso62jU"
      },
      "outputs": [],
      "source": [
        "# CE\n",
        "sasrec_scores_ce = sasrec_model_scoring(model_ce, testset, data_description)\n",
        "downvote_seen_items(sasrec_scores_ce, testset, data_description)\n",
        "\n",
        "sasrec_recs_ce = topn_recommendations(sasrec_scores_ce, topn=10)\n",
        "model_evaluate(sasrec_recs_ce, holdout, data_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-rkMp9fDsmU"
      },
      "outputs": [],
      "source": [
        "# SCE\n",
        "sasrec_scores_sce = sasrec_model_scoring(model_sce, testset, data_description)\n",
        "downvote_seen_items(sasrec_scores_sce, testset, data_description)\n",
        "\n",
        "sasrec_recs_sce = topn_recommendations(sasrec_scores_sce, topn=10)\n",
        "model_evaluate(sasrec_recs_sce, holdout, data_description)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjAyW7KPuOfP"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "e587e8b75394de48c2e2a47def3a5e72a23054844b7abdff48af37dc7e76636d"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.10"
    },
    "orig_nbformat": 4,
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "67cc7e90602c4777af7dc3e7b6af2a36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1be0fbd8ab63491aa711d6154092c0f3",
              "IPY_MODEL_2f7defdc24bc48289f9668e40c9cc4ee",
              "IPY_MODEL_4db7a72e29c447dd8278b85b1aa04314"
            ],
            "layout": "IPY_MODEL_02fee2945cab42f68c759465bbbaf3e5"
          }
        },
        "1be0fbd8ab63491aa711d6154092c0f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87195f84835b4d59b30324085cf1e367",
            "placeholder": "",
            "style": "IPY_MODEL_512fe5bc570d48008ef4405c3148fc72",
            "value": "0%"
          }
        },
        "2f7defdc24bc48289f9668e40c9cc4ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42a45a724fc04e06a9830c50fab4c9ec",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9c19b3e2d27f4e1fa584ae3b4520e924",
            "value": 0
          }
        },
        "4db7a72e29c447dd8278b85b1aa04314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a7fa3469952e457f843ebc689d59e1d6",
            "placeholder": "",
            "style": "IPY_MODEL_145c4429030147b3bf4c4d048c298252",
            "value": "0/1[00:06&lt;?,?it/s]"
          }
        },
        "02fee2945cab42f68c759465bbbaf3e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87195f84835b4d59b30324085cf1e367": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "512fe5bc570d48008ef4405c3148fc72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42a45a724fc04e06a9830c50fab4c9ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c19b3e2d27f4e1fa584ae3b4520e924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a7fa3469952e457f843ebc689d59e1d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "145c4429030147b3bf4c4d048c298252": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}